{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zggk-Z1Vvsl7",
        "outputId": "210d1571-6508-42c9-8e0b-b43bcde9ff0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: alphabets in c:\\users\\jagiraldo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install alphabets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os.path # To handle paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x__X5uy5wfbW"
      },
      "outputs": [],
      "source":[
        "en_alphabet = list(range(97, 123))\n ",
        "es_alphabet = en_alphabet.copy()\n",
        "es_alphabet.append(241)\n",
        "\n",
        "all_ascii = list(range(256))\n",
        "non_alphabetic_en = [simbol for simbol in all_ascii if simbol not in en_alphabet] \n",
        "non_alphabetic_es = [simbol for simbol in all_ascii if simbol not in es_alphabet]\n",
        "\n",
       
        "alphabets = {\n", 
        "    \"en_alphabet\": en_alphabet,\n",
        "    \"es_alphabet\": es_alphabet,\n",
        "    \"non_alphabetic_en\": non_alphabetic_en,\n",
        "    \"non_alphabetic_es\": non_alphabetic_es\n",
        " # We create our alphabets separating english from spanish and there respective non alphabetical charaters }" 
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aSj9lk_3wngg"
      },
      "outputs": [],
      "source": [
        "def scan_model(text_file:str, language=\"en\")->dict:\n",
        "\n",
        "    \"\"\"\n",
        "    Reads 'text_file' in 'language' format, clears nonalphabetic symbols and counts frequencies\n",
        "    \"\"\"\n",
        "    \n",
        "    with open(text_file, 'r', encoding='utf-8') as file:\n",
        "        text = (file.readlines())\n",
        "    all_words = \"\".join(text)\n",
        "            \n",
        "    hist = dict()\n",
        "\n",
        "    if len(all_words) != 0:\n",
        "        all_words = all_words.lower()\n",
        "        for code in alphabets[f\"non_alphabetic_{language}\"]:\n",
        "            all_words = all_words.replace(chr(code), \"\")\n",
        "\n",
        "        for code in alphabets[f\"{language}_alphabet\"]:\n",
        "            hist[chr(code)] = all_words.count(chr(code))/len(all_words)\n",
        "    \n",
        "    return hist\n",
        "\n",
        "en_model = scan_model(os.path.join(\"Train_data\",\"en_train.txt\"), \"en\") \n",
        "es_model = scan_model(os.path.join(\"Train_data\",\"es_train.txt\"), \"es\") \n",
        "# 2 models are now trained by reading texts, the english model will read harry potter and will count the amount of letter \n",
        "creating the frequencies of these(non alphabetical chars are removed), the same will be done in spanish with El quijote de la mancha \n"
         
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYm7WW5_wz7o"
      },
      "outputs": [],
      "source": [
        "from math import log\n",
        "\n",
        "def scan_test(text_file:str, language=\"en\")->str:\n",
        "\n",
        "    \"\"\"\n",
        "    Reads 'text_file' in 'language' format, clears nonalphabetic symbols\n",
        "    \"\"\"\n",
        "\n",
        "    with open(text_file, 'r', encoding='utf-8') as file:\n",
        "        text = (file.readlines())\n",
        "    all_words = \"\".join(text)\n",
        "    all_words = all_words.lower()\n",
        "    for code in alphabets[f\"non_alphabetic_{language}\"]:\n",
        "        all_words = all_words.replace(chr(code), \"\")\n",
        "\n",
        "    return all_words\n",
        "\n",
        "def likelihood(string:str, probs:dict):\n",
        "    result = 1.0\n",
        "    for letter in string:\n",
        "        result = result*probs[letter]\n",
        "\n",
        "    return result\n",
        "\n",
        "def log_likelihood(string:str, probs:dict):\n",
        "    result = 0.0\n",
        "    for letter in string:\n",
        "        if probs[letter] != 0:\n",
        "            result = result + log(probs[letter])\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6Y4Dk0_w_f1",
        "outputId": "6a164158-c0e1-4bfd-b4e3-c1e16411c006"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'log_likelihood' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m Text \u001b[39m=\u001b[39m Text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m spa_eng \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39minput\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mSi escribio en ingles marque 1 si fue en espa単ol escriba 0: \u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m english \u001b[39m=\u001b[39m log_likelihood(Text, en_model), likelihood(Text, en_model)\n\u001b[0;32m      6\u001b[0m spanish \u001b[39m=\u001b[39m log_likelihood(Text, es_model), likelihood(Text, es_model)\n\u001b[0;32m      9\u001b[0m \u001b[39mif\u001b[39;00m english[\u001b[39m1\u001b[39m]\u001b[39m>\u001b[39mspanish[\u001b[39m1\u001b[39m]:\n",
            "\u001b[1;31mNameError\u001b[0m: name 'log_likelihood' is not defined"
          ]
        }
      ],
      "source": [
        "Text = str.lower(input (\"Ingrese una frase en espa単ol o ingles: \"))\n",
        "Text = Text.replace(\" \",\"\")\n",
        "spa_eng = int(input (\"Si escribio en ingles marque 1 si fue en espa単ol escriba 0: \"))\n",
        "\n",
        "english = log_likelihood(Text, en_model), likelihood(Text, en_model)\n",
        "spanish = log_likelihood(Text, es_model), likelihood(Text, es_model)\n",
        "\n",
        "\n",
        "if english[1]>spanish[1]:\n",
        "  print(\"Predigo que es Ingles\")\n",
        "  if spa_eng == 1:\n",
        "    print(\"Se predijo correctamente con \")\n",
        "  else :\n",
        "    print(\"No pude predecir bien\")\n",
        "else:\n",
        "    print(\"Predigo que es Espa単ol\")\n",
        "    if spa_eng == 0:\n",
        "      print(\"Se predijo correctamente\")\n",
        "    else :\n",
        "      print(\"No pude predecir bien\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "ed86cd87725ed3eb26236ff68aec3c2b48ba86ad759f4f31f53d096e39ba85b5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
